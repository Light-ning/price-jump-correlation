{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2077bbd6-ecc7-4d99-a242-5f8b6a13273e",
   "metadata": {},
   "source": [
    "# 跳跃关联动量因子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581fe29-054d-403f-a069-71a175a98dbd",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10efa41-8120-4362-bf7c-6fc2da3e55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import feather\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9e939-a78c-4477-9e71-5392e039b8a5",
   "metadata": {},
   "source": [
    "## 读入日线数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2651e-ea4d-4a77-a3e2-cd307720291d",
   "metadata": {},
   "source": [
    "### 日线数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7645ffb6-5bff-4f9a-99f5-e289b6709c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1d = feather.read_dataframe('../data/StockPriceK1d_20241231.feather')\n",
    "price_1d = price_1d[(price_1d['date'] >= '2019-01-01') & (price_1d['date'] <= '2024-12-31')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0e76f-b227-4032-92dd-c4ed0850d05c",
   "metadata": {},
   "source": [
    "### 跳跃收益数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b050f9-1938-4e31-956d-f989eddfafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump = feather.read_dataframe('../data/jump/jump.feather')\n",
    "price_1d = pd.merge(\n",
    "    price_1d,\n",
    "    jump[['issue', 'date', 'ret_jump', 'ret_nojump', 'ret_posjump', 'ret_negjump']],\n",
    "    on=['issue', 'date'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2174b3-3d2a-4d73-a02a-22d7de300841",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1d.loc[\n",
    "    (price_1d['ret'] < 0.01) & (price_1d['ret'] > -0.01),\n",
    "    ['ret_jump', 'ret_nojump', 'ret_posjump', 'ret_negjump']\n",
    "] = np.nan\n",
    "\n",
    "price_1d['log_ret'] = np.log(1 + price_1d['ret'])\n",
    "price_1d['ret_nojump'] = price_1d['ret_nojump'].fillna(price_1d['log_ret'])\n",
    "price_1d = price_1d.fillna(0.)\n",
    "price_1d['ret_without_posjump'] = price_1d['ret_nojump'] + price_1d['ret_negjump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26538a9a-b538-40eb-b351-d4965331472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1d = price_1d.set_index('issue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312e519-443e-47af-bcee-c98d12fa484c",
   "metadata": {},
   "source": [
    "### 调仓日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1ee3c1-1018-49e0-aa3a-a493bbb9e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-08-01'\n",
    "end_date = '2025-01-01'\n",
    "df_adj = feather.read_dataframe('../data/adj_date_daily.feather')\n",
    "adj_date = df_adj.loc[\n",
    "    (df_adj['adj_date'] >= start_date) &\n",
    "    (df_adj['adj_date'] <= end_date), 'adj_date'\n",
    "].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2d2e9-c11b-47df-8b82-cdf3c08fe2b7",
   "metadata": {},
   "source": [
    "## 计算过去 20 天收益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef9e225-ef09-4f53-904b-cc8e0b0f6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ret_cols = ['log_ret', 'ret_nojump', 'ret_posjump', 'ret_negjump', 'ret_without_posjump']\n",
    "ret_20_cols = [col + '_20' for col in ret_cols]\n",
    "price_1d[ret_20_cols] = (\n",
    "    price_1d\n",
    "        .groupby('issue')[ret_cols]\n",
    "        .transform(lambda x: x.rolling(20).apply(np.sum, raw=True))\n",
    ")\n",
    "price_1d['ret_20'] = np.exp(price_1d['log_ret_20']) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9038c-d987-4801-bb7c-769a80539854",
   "metadata": {},
   "source": [
    "## 跳跃关联动量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd19a3-6f20-4b6b-a256-838b18d55642",
   "metadata": {},
   "source": [
    "### 读入相关性 & 矩阵展平 & 稀疏化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4401cfb1-894a-4535-bb1b-c74573be847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(date, factor_type: str):\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    corr = feather.read_dataframe(f'../data/corr_daily/{year}/corr_{factor_type}_{date_str}.feather')\n",
    "    np.fill_diagonal(corr.values, 0)\n",
    "    corr = (\n",
    "        corr\n",
    "            .stack()\n",
    "            .rename('corr')\n",
    "            .rename_axis(['issue_i', 'issue_j'])\n",
    "    )\n",
    "    corr = corr.reset_index()\n",
    "    \n",
    "    med = corr.loc[corr['corr'] > 0, 'corr'].median()\n",
    "    corr.loc[corr['corr'] < med, 'corr'] = 0\n",
    "\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57293c9-03e0-45b3-80c9-c828b09555a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_sparse(date, factor_type: str, upper_only: bool = True):\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    corr = feather.read_dataframe(f'../data/corr_daily/{year}/corr_{factor_type}_{date_str}.feather')\n",
    "    corr_np = corr.values\n",
    "    np.fill_diagonal(corr_np, 0.0)\n",
    "\n",
    "    pos = corr_np > 0\n",
    "    med = np.nanmedian(corr_np[pos]) if np.any(pos) else 0.0\n",
    "    mask = (corr_np >= med)\n",
    "    idx_i, idx_j = np.where(mask)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'issue_i': corr.index.values[idx_i],\n",
    "        'issue_j': corr.columns.values[idx_j],\n",
    "        'corr': corr_np[mask]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea8788-ad13-41b6-bb21-1c090f7e941e",
   "metadata": {},
   "source": [
    "### 计算绝对动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ab47a9-f926-4bab-9fe3-939ec74eeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peer_ret_calc(corr_ret:pd.DataFrame, ret_cols=['ret_20']):\n",
    "    nume = corr_ret[ret_cols].mul(corr_ret['corr'], axis=0).sum()\n",
    "    deno = corr_ret['corr'].sum()\n",
    "    if deno == 0:\n",
    "        return None\n",
    "    peer_ret = nume / deno\n",
    "    return peer_ret\n",
    "\n",
    "def get_peer_abs_ret(date, corr:pd.DataFrame, ret_cols=['ret_20'], peer_cols=None):\n",
    "    prc_date = price_1d.loc[price_1d['date'] == date, ret_cols].reset_index()\n",
    "    corr_ret = pd.merge(\n",
    "        corr,\n",
    "        prc_date,\n",
    "        left_on='issue_j',\n",
    "        right_on='issue',\n",
    "        how='left'\n",
    "    )\n",
    "    corr_ret = corr_ret.fillna(0.)\n",
    "    \n",
    "    peer_ret = (\n",
    "        corr_ret\n",
    "            .groupby('issue_i')[['corr'] + ret_cols]\n",
    "            .apply(peer_ret_calc, ret_cols=ret_cols)\n",
    "    )\n",
    "    peer_ret = peer_ret.dropna()\n",
    "    if peer_cols != None:\n",
    "        map_ret_peer = {ret: peer for ret, peer in zip(ret_cols, peer_cols)}\n",
    "    else:\n",
    "        map_ret_peer = {ret: ret.replace('_20', '').replace('ret', 'peer') for ret in ret_cols}\n",
    "    peer_ret = peer_ret.rename(columns=map_ret_peer)\n",
    "    peer_ret = peer_ret.rename_axis('issue')\n",
    "    peer_ret = peer_ret.reset_index()\n",
    "\n",
    "    peer_ret = pd.merge(\n",
    "        peer_ret,\n",
    "        prc_date[['issue', 'ret_20']],\n",
    "        on='issue',\n",
    "        how='left'\n",
    "    )\n",
    "    peer_ret = peer_ret.dropna(subset='ret_20')\n",
    "    peer_ret['date'] = date\n",
    "    return peer_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e492c99e-3c74-48e4-9e87-8546c3ee0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peer_abs_ret_fast(date, corr: pd.DataFrame,\n",
    "                          ret_cols=['ret_20'], peer_cols=None):\n",
    "    # 1) 取当日收益，并索引到 issue，避免后面 merge\n",
    "    prc = price_1d.loc[price_1d['date'] == date, ret_cols]\n",
    "\n",
    "    # 2) 用 join 替换 merge（基于索引的连接更快），只引入需要列\n",
    "    #    corr 只保留必要列，避免大表拷贝\n",
    "    c = corr[['issue_i', 'issue_j', 'corr']].copy()\n",
    "    c = c.join(prc, on='issue_j', how='left')          # 在右侧按 issue_j 对应到 ret 列\n",
    "\n",
    "    # 3) 只对 ret 列做 fillna(0)（不少数据里 ret 缺失要当 0 处理）\n",
    "    if ret_cols:\n",
    "        c[ret_cols] = c[ret_cols].fillna(0.0)\n",
    "\n",
    "    # 4) 计算分子与分母：对每个 issue_i 汇总 corr*ret 与 corr\n",
    "    #    注意：一次性对所有 ret_cols 做按行乘，再 groupby.sum\n",
    "    weighted_ret_sum = c[ret_cols].multiply(c['corr'], axis=0)\\\n",
    "                                  .groupby(c['issue_i'], observed=True, sort=False).sum()\n",
    "    corr_sum = c.groupby('issue_i', observed=True, sort=False)['corr'].sum()\n",
    "\n",
    "    # 5) 加权均值（分母为 0 的行会产生 NaN，正好用于过滤）\n",
    "    peer_ret = weighted_ret_sum.div(corr_sum, axis=0)\n",
    "\n",
    "    # 6) 列名映射\n",
    "    if peer_cols is not None:\n",
    "        rename_map = {ret: peer for ret, peer in zip(ret_cols, peer_cols)}\n",
    "    else:\n",
    "        rename_map = {ret: ret.replace('_20', '').replace('ret', 'peer') for ret in ret_cols}\n",
    "    peer_ret = peer_ret.rename(columns=rename_map)\n",
    "\n",
    "    # 7) 把 index 变回列名 issue\n",
    "    peer_ret.index.name = 'issue'\n",
    "    peer_ret = peer_ret.reset_index()\n",
    "\n",
    "    # 8) 只把需要的真实收益拼回（利用索引 reindex 避免再次 merge）\n",
    "    #    这里把 ret_20 拼到 issue 上；如果你需要别的列也可以同理处理\n",
    "    r20 = prc['ret_20'].rename('ret_20')\n",
    "    peer_ret['ret_20'] = r20.reindex(peer_ret['issue']).values\n",
    "\n",
    "    # 9) 丢掉 ret_20 为空的（极少量无法匹配的）\n",
    "    peer_ret = peer_ret.dropna(subset=['peer', 'ret_20'])\n",
    "    peer_ret['date'] = date\n",
    "    return peer_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad88bfa-f35d-49a4-b203-44c6ad1fbb88",
   "metadata": {},
   "source": [
    "### 计算相对动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2cc0c7-e8e6-464c-b076-350e08ac751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peer_relative_ret(peer_ret:pd.DataFrame, peer_cols=['peer_ret'], relative_cols=None, plot=False):\n",
    "    x = peer_ret['ret_20']\n",
    "    x = sm.add_constant(x)\n",
    "    y = peer_ret[peer_cols]\n",
    "    result = sm.OLS(y, x).fit()\n",
    "\n",
    "    relative_ret = result.resid\n",
    "    if relative_cols != None:\n",
    "        map_peer_relative = {peer: relative for peer, relative in zip(peer_cols, relative_cols)}\n",
    "    else:\n",
    "        map_peer_relative = {peer: peer.replace('peer', 'relative') for peer in peer_cols}\n",
    "    relative_ret = relative_ret.rename(columns=map_peer_relative)\n",
    "    return relative_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4b6c1-9a0c-4d5f-ae31-e26a380986d2",
   "metadata": {},
   "source": [
    "### 规模运算 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbab318-01dd-4829-98e1-29dd3c4ec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peer_ret_factor(date:np.datetime64, factor_type:str, ret_cols=['ret_20'], peer_cols=None, relative_cols=None):\n",
    "    if peer_cols is None:\n",
    "        peer_cols = [ret_col.replace('_20', '').replace('ret', 'peer') for ret_col in ret_cols]\n",
    "    if relative_cols is None:\n",
    "        relative_cols = [peer_col.replace('peer', 'relative') for peer_col in peer_cols]\n",
    "\n",
    "    corr = get_correlation_sparse(date, factor_type)\n",
    "    prd = get_peer_abs_ret_fast(\n",
    "        date, corr,\n",
    "        ret_cols=ret_cols, peer_cols=peer_cols\n",
    "    )\n",
    "    \n",
    "    rrd = get_peer_relative_ret(\n",
    "        prd,\n",
    "        peer_cols=peer_cols, relative_cols=relative_cols\n",
    "    )\n",
    "    prd = pd.concat([prd, rrd], axis=1)\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c09007-7e00-449e-b531-7343f16e3361",
   "metadata": {},
   "source": [
    "#### 计算所有日期所有因子并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e146ca-50b3-42f9-8fcb-82db5ebc9704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acd45a86b6d46118ec4eddb32324428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret_cols = ['ret_20', 'ret_nojump_20', 'ret_posjump_20', 'ret_negjump_20', 'ret_without_posjump_20']\n",
    "peer_cols = [ret_col.replace('_20', '').replace('ret', 'peer') for ret_col in ret_cols]\n",
    "relative_cols = [peer_col.replace('peer', 'relative') for peer_col in peer_cols]\n",
    "dirname = '../data/peer_ret_daily/'\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "for date in tqdm(adj_date):\n",
    "    prd_num = get_peer_ret_factor(\n",
    "        date, 'num',\n",
    "        ret_cols=ret_cols,\n",
    "        peer_cols=peer_cols,\n",
    "        relative_cols=relative_cols\n",
    "    )\n",
    "    prd_size = get_peer_ret_factor(\n",
    "        date, 'size',\n",
    "        ret_cols=ret_cols,\n",
    "        peer_cols=peer_cols,\n",
    "        relative_cols=relative_cols\n",
    "    )\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    os.makedirs(dirname + f'/{year}/', exist_ok=True)\n",
    "    feather.write_dataframe(prd_num, dirname + f'/{year}/prd_num_{date_str}.feather')\n",
    "    feather.write_dataframe(prd_size, dirname + f'/{year}/prd_size_{date_str}.feather')\n",
    "    del prd_num, prd_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde61efa-bffb-45ea-b629-2fad0ada2324",
   "metadata": {},
   "source": [
    "#### 整合因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60122c6a-f2c8-4b9d-831f-e1ccf43cf7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../data/peer_ret_daily/'\n",
    "peer_ret_num = None\n",
    "peer_ret_size = None\n",
    "for date in adj_date:\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    prd_num = feather.read_dataframe(dirname + f'/{year}/prd_num_{date_str}.feather')\n",
    "    peer_ret_num = pd.concat([peer_ret_num, prd_num], axis=0)\n",
    "    prd_size = feather.read_dataframe(dirname + f'/{year}/prd_size_{date_str}.feather')\n",
    "    peer_ret_size = pd.concat([peer_ret_size, prd_size], axis=0)\n",
    "\n",
    "for peer, relative in zip(peer_cols, relative_cols):\n",
    "    partial_num = peer_ret_num[['date', 'issue', peer, relative]]\n",
    "    partial_num = partial_num.rename(columns={peer: 'peer_ret', relative: 'peer_relative_ret'})\n",
    "    feather.write_dataframe(partial_num, dirname + peer + '_num.feather')\n",
    "\n",
    "    partial_size = peer_ret_size[['date', 'issue', peer, relative]]\n",
    "    partial_size = partial_size.rename(columns={peer: 'peer_ret', relative: 'peer_relative_ret'})\n",
    "    feather.write_dataframe(partial_size, dirname + peer + '_size.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142fa00-2c5b-43ce-b5c5-253ea9648f99",
   "metadata": {},
   "source": [
    "### 将非跳跃动量因子与负跳跃动量因子相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6207b-89ea-4873-bdb3-4af0ca7db489",
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_nojump_num = feather.read_dataframe('../data/peer_ret_daily/peer_nojump_num.feather')\n",
    "peer_negjump_num = feather.read_dataframe('../data/peer_ret_daily/peer_negjump_num.feather')\n",
    "peer_without_posjump_1_num = pd.DataFrame(data={\n",
    "    'date': peer_nojump_num['date'],\n",
    "    'issue': peer_nojump_num['issue'],\n",
    "    'peer_relative_ret': peer_nojump_num['peer_relative_ret'] + peer_negjump_num['peer_relative_ret']\n",
    "})\n",
    "feather.write_dataframe(peer_without_posjump_1_num, '../data/peer_ret_daily/peer_without_posjump_1_num.feather')\n",
    "\n",
    "peer_nojump_size = feather.read_dataframe('../data/peer_ret_daily/peer_nojump_size.feather')\n",
    "peer_negjump_size = feather.read_dataframe('../data/peer_ret_daily/peer_negjump_size.feather')\n",
    "peer_without_posjump_1_size = pd.DataFrame(data={\n",
    "    'date': peer_nojump_size['date'],\n",
    "    'issue': peer_nojump_size['issue'],\n",
    "    'peer_relative_ret': peer_nojump_size['peer_relative_ret'] + peer_negjump_size['peer_relative_ret']\n",
    "})\n",
    "feather.write_dataframe(peer_without_posjump_1_size, '../data/peer_ret_daily/peer_without_posjump_1_size.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c5f72-2359-4788-9935-c80aef101642",
   "metadata": {},
   "source": [
    "## 等权复合频率 / 幅度因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2392cf3-1199-4430-a887-901f380299bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = feather.read_dataframe('../data/peer_ret_daily/peer_without_posjump_num.feather')\n",
    "size = feather.read_dataframe('../data/peer_ret_daily/peer_without_posjump_size.feather')\n",
    "num = num.reset_index(drop=True)\n",
    "size = size.reset_index(drop=True)\n",
    "peer_without_posjump = pd.DataFrame(data={\n",
    "    'date': num['date'],\n",
    "    'issue': num['issue'],\n",
    "    'peer_relative_ret': num['peer_relative_ret'] + size['peer_relative_ret']\n",
    "})\n",
    "feather.write_dataframe(peer_without_posjump, '../data/peer_ret_daily/peer_without_posjump.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
