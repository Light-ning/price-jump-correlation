{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2e85e8-5cbf-4e57-adc8-78bb8fe1ce43",
   "metadata": {},
   "source": [
    "# 关联跳跃和跳跃关联度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24c4c9-8f5c-4dd9-8062-2ce39e44eef1",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc96d39-42f0-46ee-a2c7-beb77b8327ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import feather\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170cda2-d02c-47fe-8b2c-7f4dac9ba525",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43411b4-bce4-48e8-919b-5759f1816e51",
   "metadata": {},
   "source": [
    "### 读入日线数据及处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49f9c87-7137-4945-bdc0-90f9e55201a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1d = feather.read_dataframe('../data/StockPriceK1d_20241231.feather')\n",
    "price_1d = price_1d[(price_1d['date'] >= '2019-01-01') & (price_1d['date'] <= '2024-12-31')]\n",
    "price_1d = price_1d[(price_1d['ret'] > 0.01) | (price_1d['ret'] < -0.01)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3777b0-6904-4e28-a279-127317fad65a",
   "metadata": {},
   "source": [
    "### 股价跳跃数据及处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ca9682-873f-4877-ae8d-d38757e6e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump = feather.read_dataframe('../data/jump/jump.feather')\n",
    "jump['date'] = pd.to_datetime(jump['date'])\n",
    "jump = pd.merge(\n",
    "    jump,\n",
    "    price_1d[['issue', 'date']],\n",
    "    on=['issue', 'date'],\n",
    "    how='inner'\n",
    ")\n",
    "jump['sign'] = jump['ret_jump'].apply(np.sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6beae8-5c90-43db-a8fa-4bdf438ff2fb",
   "metadata": {},
   "source": [
    "### 调仓日和对应的构建关联度开始时间 (120 天前)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9113afe-e161-470f-be7f-59169184963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_date = price_1d['date'].sort_values().unique()\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2025-01-01'\n",
    "mes = pd.date_range(start=start_date, end=end_date, freq='1ME')\n",
    "adj_date = np.array([], dtype=np.datetime64)\n",
    "calc_start_date = np.array([], dtype=np.datetime64)\n",
    "\n",
    "for me in mes:\n",
    "    trade_date_before = trade_date[trade_date <= me]\n",
    "    ad = trade_date_before[-1]\n",
    "    adj_date = np.append(adj_date, ad)\n",
    "    if (len(trade_date_before) > 120):\n",
    "        csd = trade_date_before[-120]\n",
    "    else:\n",
    "        csd = trade_date_before[0]\n",
    "    calc_start_date = np.append(calc_start_date, csd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917197b3-23f3-443e-a3ec-146951f466df",
   "metadata": {},
   "source": [
    "### 公司列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c76bab5-9beb-4ccf-8f50-0cc39d31d7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0409c82aa9ac4373890a97b82383c3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "issues = pd.DataFrame(columns=['date', 'issue'])\n",
    "tqdm_date = tqdm(zip(adj_date, calc_start_date), total=len(adj_date))\n",
    "for ad, csd in tqdm_date:\n",
    "    idx_date = (price_1d['date'] >= csd) & (price_1d['date'] <= ad)\n",
    "    issues_date = price_1d.loc[idx_date, 'issue'].sort_values().unique()\n",
    "    issues_date = pd.DataFrame({'date': ad, 'issue': issues_date})\n",
    "    if issues.empty:\n",
    "        issues = issues_date\n",
    "    else:\n",
    "        issues = pd.concat([issues, issues_date])\n",
    "issues = issues.set_index('date')\n",
    "feather.write_dataframe(issues, '../data/issues.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85e7bbe-cf0d-4f5f-869d-f9836a0b46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_tot = issues['issue'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849cd4a-ce3b-4fa6-92fc-0e16cc3e0732",
   "metadata": {},
   "source": [
    "## 关联跳跃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefd7ef-3444-43a2-aeb2-f6f102d46ea1",
   "metadata": {},
   "source": [
    "### 前一日后一日跳跃方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0a09580-2e11-42d0-9894-cc5de4314ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1036\\776737670.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  jump_expand['jump'] = jump_expand['jump'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "jump_plus1 = jump[['issue', 'date', 'sign']].copy()\n",
    "jump_plus1['date'] = jump_plus1['date'] + pd.Timedelta('1d')\n",
    "jump_plus1 = jump_plus1.rename(columns={'sign': 'sign_yest'})\n",
    "jump_expand = pd.merge(\n",
    "    jump.reset_index(),\n",
    "    jump_plus1,\n",
    "    on=['issue', 'date'],\n",
    "    how='outer'\n",
    ")\n",
    "jump_minus1 = jump[['issue', 'date', 'sign']].copy()\n",
    "jump_minus1['date'] = jump_minus1['date'] - pd.Timedelta('1d')\n",
    "jump_minus1 = jump_minus1.rename(columns={'sign': 'sign_tomo'})\n",
    "jump_expand = pd.merge(\n",
    "    jump_expand,\n",
    "    jump_minus1,\n",
    "    on=['issue', 'date'],\n",
    "    how='outer'\n",
    ")\n",
    "jump_expand['index'] = jump_expand['index'].fillna(-1.).astype(int)\n",
    "jump_expand[['sign', 'sign_yest', 'sign_tomo']] = jump_expand[['sign', 'sign_yest', 'sign_tomo']].fillna(0.)\n",
    "jump_expand['jump'] = jump_expand['jump'].fillna(False)\n",
    "jump_expand['ret_jump'] = jump_expand['ret_jump'].fillna(0.)\n",
    "jump_expand['year_mon'] = jump_expand['date'].dt.year * 100 + jump_expand['date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29cad8-06d0-4c34-a2a2-d48ffbae3aec",
   "metadata": {},
   "source": [
    "### 关联跳跃矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c523299-b95b-4b6e-8cc3-964fa8d840a1",
   "metadata": {},
   "source": [
    "index: 每一次跳跃\n",
    "\n",
    "column: 每一家公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a705e3f1-f5d2-45d0-842d-99515fa086e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global jump_corr\n",
    "jump_corr = pd.DataFrame(data=False, index=jump.index, columns=issues_tot, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d75f3-63f3-4c5a-951e-050ba8b46d6d",
   "metadata": {},
   "source": [
    "### 找出一日内的关联跳跃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881344d9-86df-4b62-94b8-87dbb1b21116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_corr(jump_date):\n",
    "    global jump_corr\n",
    "\n",
    "    idx_pos = jump_date.loc[jump_date['sign'] == 1, 'index']\n",
    "    idx_pos_corr = (jump_date['sign'] == 1) | (jump_date['sign_yest'] == 1) | (jump_date['sign_tomo'] == 1)\n",
    "    issues_pos = jump_date.loc[idx_pos_corr, 'issue'].to_numpy()\n",
    "    jump_corr.loc[idx_pos, issues_pos] = True\n",
    "    \n",
    "    idx_neg = jump_date.loc[jump_date['sign'] == -1, 'index']\n",
    "    idx_neg_corr = (jump_date['sign'] == -1) | (jump_date['sign_yest'] == -1) | (jump_date['sign_tomo'] == -1)\n",
    "    issues_neg = jump_date.loc[idx_neg_corr, 'issue'].to_numpy()\n",
    "    jump_corr.loc[idx_neg, issues_neg] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9352a-63cc-4698-9f7f-da63a4dce30f",
   "metadata": {},
   "source": [
    "### 关联跳跃 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302ed89d-92da-4abe-a353-cd510d867bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "jump_expand.groupby('date')[['issue', 'index', 'sign', 'sign_yest', 'sign_tomo']].apply(identify_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3ca8ee-3c4f-4036-b31c-d385dddec34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 23s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.makedirs('../data/corr/', exist_ok=True)\n",
    "feather.write_dataframe(jump_corr, '../data/corr/jump_corr.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a2c2a-a6bf-49d6-af09-bea26864ba16",
   "metadata": {},
   "source": [
    "## 跳跃关联度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07499282-23b7-4255-9ac6-2b77cbb4a05e",
   "metadata": {},
   "source": [
    "### 一家公司一个调仓日的跳跃关联度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb967a0d-7fb1-4548-91cd-aec0824e8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_calc(jump, jump_corr_date):\n",
    "    idx = jump.index\n",
    "    sum_num = jump['jump'].count()\n",
    "    corr_num = jump_corr_date.loc[idx].sum() / sum_num\n",
    "    abs_ret_jump = jump['ret_jump'].apply(np.abs)\n",
    "    sum_size = abs_ret_jump.sum()\n",
    "    corr_size = jump_corr_date.loc[idx].mul(abs_ret_jump, axis=0).sum() / sum_size\n",
    "\n",
    "    corr_num = corr_num\n",
    "    corr_num['type'] = 'num'\n",
    "    corr_size = corr_size\n",
    "    corr_size['type'] = 'size'\n",
    "    \n",
    "    return pd.concat([corr_num, corr_size], axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccfc28e-f0f0-4b0f-8bbf-be6725254282",
   "metadata": {},
   "source": [
    "### 所有公司每个调仓日的跳跃关联度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa12e16-fa3e-4553-83ea-8cb5d9d5f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8ca294e22f4612b2494914c0069f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Adjusting Date:   0%|          | 0/7 [00:00<?, ?days/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 54s\n",
      "Wall time: 8min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# remove_num = []\n",
    "# remove_size = []\n",
    "\n",
    "tqdm_date = tqdm(\n",
    "    zip(adj_date[-7:], calc_start_date[-7:]),\n",
    "    total=len(adj_date[-7:]),\n",
    "    desc='Processing Adjusting Date',\n",
    "    unit='days'\n",
    ")\n",
    "\n",
    "os.makedirs('../data/corr/', exist_ok=True)\n",
    "os.makedirs('../data/N_connect/', exist_ok=True)\n",
    "\n",
    "for ad, csd in tqdm_date:\n",
    "    ad_str = ad.strftime('%Y%m%d')\n",
    "    issues_date = issues.loc[ad, 'issue'].to_numpy()\n",
    "    jump_corr_date = jump_corr.loc[(jump['date'] <= ad) & (jump['date'] >= csd), issues_date]\n",
    "    jump_date = jump[(jump['date'] <= ad) & (jump['date'] >= csd)]\n",
    "    \n",
    "    corr = (\n",
    "        jump_date\n",
    "            .groupby('issue')[['jump', 'ret_jump']]\n",
    "            .apply(corr_calc, jump_corr_date=jump_corr_date)\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    corr_num = (\n",
    "        corr[corr['type'] == 'num']\n",
    "            .drop(columns=['level_1', 'type'])\n",
    "            .set_index('issue')\n",
    "            .reindex(index=issues_date, columns=issues_date, fill_value=0)\n",
    "    )\n",
    "    corr_size = (\n",
    "        corr[corr['type'] == 'size']\n",
    "            .drop(columns=['level_1', 'type'])\n",
    "            .set_index('issue')\n",
    "            .reindex(index=issues_date, columns=issues_date, fill_value=0)\n",
    "    )\n",
    "    feather.write_dataframe(corr_num, f'../data/corr/corr_num_{ad_str}.feather')\n",
    "    feather.write_dataframe(corr_size, f'../data/corr/corr_size_{ad_str}.feather')\n",
    "    \n",
    "    # med_num = np.median(corr_num)\n",
    "    # corr_num[corr_num <= med_num] = 0\n",
    "    # med_size = np.median(corr_size)\n",
    "    # corr_size[corr_size <= med_size] = 0\n",
    "    # feather.write_dataframe(corr_num, f'../data/corr/sparse_corr_num_{ad_str}.feather')\n",
    "    # feather.write_dataframe(corr_size, f'../data/corr/sparse_corr_size_{ad_str}.feather')\n",
    "    \n",
    "    # r_num = ((corr_num > 0).sum() <= 1).sum(axis=1)\n",
    "    # remove_num.append(r_num / len(issues_date))\n",
    "    # r_size = ((corr_size > 0).sum() <= 1).sum(axis=1)\n",
    "    # remove_size.append(r_size / len(issues_date))\n",
    "    \n",
    "    # N_connect_num = (corr_num > 0).sum(axis=1)\n",
    "    # N_connect_num = pd.concat([corr_num[['issue', 'date', 'type']], N_connect_num], axis=1)\n",
    "    # feather.write_dataframe(N_connect_num, f'../data/N_connect/N_connect_num_{ad_str}.feather')\n",
    "    # N_connect_size = (corr_size[issues] > 0).sum(axis=1)\n",
    "    # N_connect_size = N_connect_size.rename('N_connect')\n",
    "    # N_connect_size = pd.concat([corr_size[['issue', 'date', 'type']], N_connect_size], axis=1)\n",
    "    # feather.write_dataframe(N_connect_size, f'../data/N_connect/N_connect_size_{ad_str}.feather')\n",
    "        \n",
    "    del corr, corr_num, corr_size\n",
    "del jump_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f06cf9-84a5-4a47-954d-a35ad7b65f1d",
   "metadata": {},
   "source": [
    "### 合并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de728a6f-18bf-46b1-b7b0-30b35a68dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_connect_num = pd.DataFrame(columns=['issue', 'date', 'N_connect'])\n",
    "# N_connect_size = pd.DataFrame(columns=['issue', 'date', 'N_connect'])\n",
    "# for ad in adj_date:\n",
    "#     ad_str = ad.strftime('%Y%m%d')\n",
    "#     num_daily = feather.read_dataframe(f'../data/N_connect/N_connect_num_{ad_str}.feather')\n",
    "#     size_daily = feather.read_dataframe(f'../data/N_connect/N_connect_size_{ad_str}.feather')\n",
    "#     if N_connect_num.empty:\n",
    "#         N_connect_num = num_daily\n",
    "#     else:\n",
    "#         N_connect_num = pd.concat([N_connect_num, num_daily])\n",
    "#     if N_connect_size.empty:\n",
    "#         N_connect_size = size_daily\n",
    "#     else:\n",
    "#         N_connect_size = pd.concat([N_connect_size, size_daily])\n",
    "# feather.write_dataframe(N_connect_num, '../data/N_connect/N_connect_num.feather')\n",
    "# feather.write_dataframe(N_connect_size, '../data/N_connect/N_connect_size.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
