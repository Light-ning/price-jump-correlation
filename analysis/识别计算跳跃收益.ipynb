{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae4eb46-93f5-4f07-b1d4-580a8970b737",
   "metadata": {},
   "source": [
    "# 识别计算跳跃收益"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc9230-eb2f-48cc-bf55-4a90ed006cd7",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73926c0b-eae3-4efa-9cef-d68e17547141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import feather\n",
    "import math\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import swifter\n",
    "from joblib import Parallel, delayed\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddad00b-aa9c-4f0d-a0b2-e80c91d5c6f3",
   "metadata": {},
   "source": [
    "## 读入测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d51770-b8ad-4658-a165-cc194ad8fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_1m = feather.read_dataframe('../data/StockPriceK1m/2024/StockPriceK1m_20240102.feather')\n",
    "price_1m['date'] = pd.to_datetime(price_1m['date'].astype(str))\n",
    "price_1d = feather.read_dataframe('../data/StockPriceK1d_20240630.feather')\n",
    "price_1d['date'] = pd.to_datetime(price_1d['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820b12a-8c96-47dc-8114-f5382a218b76",
   "metadata": {},
   "source": [
    "## 处理筛选日线数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4094420-2f38-4ef1-aff0-0def842ea2e3",
   "metadata": {},
   "source": [
    "剔除上市不足 180 天、停牌、涨停股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fc9d75-cfaf-47e1-90db-ac966b11f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPO_time(price_1d, timedelta='180D'):\n",
    "    start_date = price_1d['date'].min()\n",
    "    idx_ipo = price_1d['date'] >= start_date + pd.Timedelta(timedelta)\n",
    "    return price_1d[idx_ipo]\n",
    "\n",
    "price_1d = price_1d.groupby('issue').apply(IPO_time)\n",
    "price_1d = price_1d[(~price_1d['is_limit_buy'].astype(bool)) & (~price_1d['is_limit_sell'].astype(bool))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054195a9-88e8-48ef-b7b1-8d9ab62a2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_date = (price_1d['date'] >= '2019-01-01') & (price_1d['date'] <= '2024-12-31')\n",
    "price_1d = price_1d[idx_date]\n",
    "price_1d = price_1d.set_index(['issue', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f64e1f-ae06-470b-bcb9-13c3c873f400",
   "metadata": {},
   "source": [
    "## 定义跳跃统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b36b5b-3876-4956-af35-f20777d36c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu(p: float):\n",
    "    return (2 ** (p / 2)) * math.gamma((p + 1) / 2) / np.sqrt(np.pi)\n",
    "\n",
    "mu1 = mu(1)\n",
    "mu6 = mu(6)\n",
    "\n",
    "def JS(ret, log_ret):\n",
    "    n_series, n_points = ret.shape\n",
    "    \n",
    "    abs_log_ret = np.abs(log_ret)\n",
    "    \n",
    "    window_size = 6\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(\n",
    "        abs_log_ret, window_shape=window_size, axis=1\n",
    "    )\n",
    "    prod_6 = np.prod(windows, axis=-1)\n",
    "    sum_prod_6 = np.sum(prod_6, axis=1)\n",
    "    \n",
    "    coef_Omega = (mu6 / 9) * ((n_points ** 3) * (mu1 ** -6) / (n_points - 5))\n",
    "    Omega_SwV = coef_Omega * sum_prod_6\n",
    "    \n",
    "    SwV_N = 2 * np.sum(ret - log_ret, axis=1)\n",
    "    \n",
    "    window_size_2 = 2\n",
    "    windows_2 = np.lib.stride_tricks.sliding_window_view(\n",
    "        abs_log_ret, window_shape=window_size_2, axis=1\n",
    "    )\n",
    "    prod_2 = np.prod(windows_2, axis=-1)\n",
    "    sum_prod_2 = np.sum(prod_2, axis=1)\n",
    "    \n",
    "    coef_V = 1 / mu1\n",
    "    V_01 = coef_V * sum_prod_2\n",
    "    \n",
    "    RV_N = np.sum(log_ret ** 2, axis=1)\n",
    "    \n",
    "    valid_mask = (Omega_SwV != 0) & (SwV_N != 0)\n",
    "    js = np.full(n_series, np.nan)\n",
    "    \n",
    "    if np.any(valid_mask):\n",
    "        valid_idx = np.where(valid_mask)[0]\n",
    "        js[valid_idx] = n_points * (V_01[valid_idx] / np.sqrt(Omega_SwV[valid_idx])) * (1 - RV_N[valid_idx] / SwV_N[valid_idx])\n",
    "    \n",
    "    return js[0] if n_series == 1 else js\n",
    "\n",
    "def pvalue(js: float):\n",
    "    cdf = stats.norm.cdf(js, loc=0, scale=1)\n",
    "    return 2 * min(cdf, 1 - cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadbda6b-6aba-4855-8560-8414080cc82b",
   "metadata": {},
   "source": [
    "## 识别跳跃, 计算收益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fe7a69-baa1-48ad-a7dd-b27a82f01ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_identify(ret, log_ret):\n",
    "    n = len(ret)\n",
    "    jump = np.full(n, False, dtype=bool)\n",
    "    med = np.median(ret)\n",
    "    log_med = np.median(log_ret)\n",
    "    ret_c = ret.copy()\n",
    "    log_ret_c = log_ret.copy()\n",
    "    js0 = JS(ret_c.reshape(1, n), log_ret_c.reshape(1, n))\n",
    "    p = pvalue(js0)\n",
    "    js0_pre = js0\n",
    "    \n",
    "    while (p < 0.05):\n",
    "        ret_mat = np.tile(ret_c, (n, 1))\n",
    "        log_ret_mat = np.tile(log_ret_c, (n, 1))\n",
    "        np.fill_diagonal(ret_mat, med)\n",
    "        np.fill_diagonal(log_ret_mat, log_med)\n",
    "        js = JS(ret_mat, log_ret_mat)\n",
    "        \n",
    "        js_diff = np.abs(js0) - np.abs(js)\n",
    "        idx_max = np.argmax(js_diff)\n",
    "        jump[idx_max] = True\n",
    "        ret_c[idx_max] = med\n",
    "        log_ret_c[idx_max] = log_med\n",
    "        js0 = JS(ret_c.reshape(1, n), log_ret_c.reshape(1, n))\n",
    "        p = pvalue(js0)\n",
    "        if js0 == js0_pre:\n",
    "            break\n",
    "        js0_pre = js0\n",
    "\n",
    "    return np.any(jump), log_ret[jump].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd77450f-ecb5-40c2-b5df-038717b33a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = np.append(np.arange(93000, 113000, 500), np.arange(130000, 150000, 500))\n",
    "time_start = time_start[np.where(time_start % 10000 < 6000)]\n",
    "time_end =  time_start + 400\n",
    "\n",
    "def jump_identify_price(price_1m, price_1d, date, date_next):\n",
    "    issue = price_1m.iloc[0]['issue']\n",
    "    prc = price_1m.copy()\n",
    "    start_price = prc.loc[price_1m['time'].isin(time_start), 'open'].to_numpy()\n",
    "    end_price = prc.loc[price_1m['time'].isin(time_end), 'close'].to_numpy()\n",
    "\n",
    "    try:\n",
    "        close_today = price_1d.loc[(issue, date), 'close']\n",
    "        open_next = price_1d.loc[(issue, date), 'open']\n",
    "    except KeyError:\n",
    "        df_jump = pd.DataFrame({'issue': [issue], 'date': [date], 'jump': [False], 'ret_jump': [0.]})\n",
    "        return df_jump\n",
    "        \n",
    "    start_price = np.append(start_price, close_today)\n",
    "    end_price = np.append(end_price, close_today)\n",
    "    \n",
    "    ret = (end_price - start_price) / start_price\n",
    "    log_ret = np.log(1 + ret)\n",
    "\n",
    "    flag_jump, ret_jump = jump_identify(ret, log_ret)\n",
    "    df_jump = pd.DataFrame({'issue': [issue], 'date': [date], 'jump': [flag_jump], 'ret_jump': [ret_jump]})\n",
    "    return df_jump\n",
    "\n",
    "def jump_identify_parallel(price_1m, price_1d, date, date_next):\n",
    "    groups = list(price_1m.groupby('issue'))\n",
    "    total_groups = len(groups)\n",
    "    \n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(jump_identify_price)(group[1], price_1d, '2024-01-02', '2024-01-03')\n",
    "        for group in tqdm(groups, total=total_groups, desc=\"Processing stocks\")\n",
    "    )\n",
    "    \n",
    "    return pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55f9dd-ca77-4894-be83-b098098b7714",
   "metadata": {},
   "source": [
    "## 性能测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77855fd4-8295-4e8d-a1c4-05884a460316",
   "metadata": {},
   "source": [
    "### 单公司单日性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019afc6c-bbaf-41ca-aeba-8ddfd6762673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 16.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "19.5 ms ± 22.5 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "prc = price_1m.loc[price_1m['issue'] == '000014']\n",
    "date = '2024-01-02'\n",
    "date_next = '2024-01-03'\n",
    "%timeit -n 10 -r 3 jump_identify_price(prc, price_1d, date, date_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d170892-1e9b-413b-ad29-a76a9894ffa2",
   "metadata": {},
   "source": [
    "逐行运行时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864668e2-92ed-4f76-937a-d610d3c382de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 0.0094589 s\n",
       "File: C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11892\\4145610477.py\n",
       "Function: jump_identify_price at line 5\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     5                                           def jump_identify_price(price_1m, price_1d, date, date_next):\n",
       "     6         1       4498.0   4498.0      4.8      issue = price_1m.iloc[0]['issue']\n",
       "     7         1       2530.0   2530.0      2.7      prc = price_1m.copy()\n",
       "     8         1      12269.0  12269.0     13.0      start_price = prc.loc[price_1m['time'].isin(time_start), 'open'].to_numpy()\n",
       "     9         1       8448.0   8448.0      8.9      end_price = prc.loc[price_1m['time'].isin(time_end), 'close'].to_numpy()\n",
       "    10                                           \n",
       "    11         1          4.0      4.0      0.0      try:\n",
       "    12         1       4796.0   4796.0      5.1          close_today = price_1d.loc[(issue, date), 'close']\n",
       "    13         1       3132.0   3132.0      3.3          open_next = price_1d.loc[(issue, date), 'open']\n",
       "    14                                               except KeyError:\n",
       "    15                                                   df_jump = pd.DataFrame({'issue': [issue], 'date': [date], 'jump': [False], 'ret_jump': [0.]})\n",
       "    16                                                   return df_jump\n",
       "    17                                           \n",
       "    18         1        268.0    268.0      0.3      start_price = np.append(start_price, close_today)\n",
       "    19         1        109.0    109.0      0.1      end_price = np.append(end_price, close_today)\n",
       "    20                                           \n",
       "    21         1         49.0     49.0      0.1      ret = (end_price - start_price) / start_price\n",
       "    22         1        241.0    241.0      0.3      log_ret = np.log(1 + ret)\n",
       "    23                                           \n",
       "    24         1      45928.0  45928.0     48.6      flag_jump, ret_jump = jump_identify(ret, log_ret)\n",
       "    25         1      12313.0  12313.0     13.0      df_jump = pd.DataFrame({'issue': [issue], 'date': [date], 'jump': [flag_jump], 'ret_jump': [ret_jump]})\n",
       "    26         1          4.0      4.0      0.0      return df_jump"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prc = price_1m.loc[price_1m['issue'] == '000014']\n",
    "date = '2024-01-02'\n",
    "date_next = '2024-01-03'\n",
    "%lprun -f jump_identify_price jump_identify_price(prc, price_1d, date, date_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588dcb81-16f4-4232-be23-fe7102a1e4b7",
   "metadata": {},
   "source": [
    "### 单线程 / 并行性能测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156daa1-408f-4c41-b214-df10821c4103",
   "metadata": {},
   "source": [
    "apply 单线程运算\n",
    "\n",
    "速度: 9.02s / 5096 公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d11087-4866-4f93-aa2c-f675846ab937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.27 s\n",
      "Wall time: 9.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_jump = price_1m.groupby('issue')[['issue', 'time', 'open', 'close']].apply(\n",
    "    jump_identify_price,\n",
    "    price_1d=price_1d,\n",
    "    date='2024-01-02',\n",
    "    date_next='2024-01-03'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e931da-23c0-4cd5-bf8a-8731abd629c8",
   "metadata": {},
   "source": [
    "使用 swifter 提速\n",
    "\n",
    "速度: 6.03s / 5096 公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c373eb18-6ca5-4b64-a23d-5237b0593e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cce2f9d1cd1418292978eae9766472f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 15:15:47,231\tINFO worker.py:1917 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.67 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_jump = price_1m.swifter.groupby('issue')[['issue', 'time', 'open', 'close']].apply(\n",
    "    jump_identify_price,\n",
    "    price_1d=price_1d,\n",
    "    date='2024-01-02',\n",
    "    date_next='2024-01-03'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f3ebe-822c-4bfc-bb57-cf9a2b9f2f07",
   "metadata": {},
   "source": [
    "使用 joblib 并行运算\n",
    "\n",
    "速度：18min4s / 5096 公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f478206-ac08-4ff7-be9d-264e4831bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_jump = jump_identify_parallel(price_1m, price_1d, '2024-01-02', '2024-01-03')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4ca3c-9e41-470a-84a0-3cb46d6e7b6d",
   "metadata": {},
   "source": [
    "## 读入分钟行情, 保存每日股价跳跃信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1880e3b7-6a39-4ba2-b573-c4484eeba184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7344e27de3824fcf9792d737a9ec7dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Daily Stocks:   0%|          | 0/1330 [00:00<?, ?days/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 10min 53s\n",
      "Wall time: 3h 13min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_series = price_1d.index.get_level_values('date')\n",
    "time_series = time_series.unique().sort_values()\n",
    "tqdm_time_series = tqdm(zip(time_series[:-1],time_series[1:]),\n",
    "                        total=len(time_series) - 1, desc='Processing Daily Stocks', unit='days')\n",
    "\n",
    "for date, date_next in tqdm_time_series:\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    price_1m = feather.read_dataframe(f'../data/StockPriceK1m/{year}/StockPriceK1m_{date_str}.feather')\n",
    "    df_jump = price_1m.groupby('issue')[['issue', 'time', 'open', 'close']].apply(\n",
    "        jump_identify_price,\n",
    "        price_1d=price_1d,\n",
    "        date=date, date_next=date_next\n",
    "    )\n",
    "    df_jump = df_jump.reset_index(drop=True)\n",
    "\n",
    "    os.makedirs(f'../data/jump/{year}/', exist_ok=True)\n",
    "    feather.write_dataframe(df_jump, f'../data/jump/{year}/jump_{date_str}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ac7287-594a-4305-b163-23fa2803f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump = pd.DataFrame(columns=['issue', 'date', 'jump', 'ret_jump'])\n",
    "for date in time_series[:-1]:\n",
    "    year = date.year\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    jump_daily = feather.read_dataframe(f'../data/jump/{year}/jump_{date_str}.feather')\n",
    "    if jump.empty:\n",
    "        jump = jump_daily\n",
    "    else:\n",
    "        jump = pd.concat([jump, jump_daily])\n",
    "jump = jump[jump['jump']]\n",
    "jump['year_mon'] = jump['date'].dt.year * 100 + jump['date'].dt.month\n",
    "feather.write_dataframe(jump, '../data/jump/jump.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
